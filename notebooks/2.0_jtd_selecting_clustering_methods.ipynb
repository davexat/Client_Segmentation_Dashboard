{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting clustering methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clustering is an unsupervised learning technique that segments a dataset into groups or clusters based on similarities between observations. In this project, the objective of clustering is to identify groups of customers with similar behaviors, providing key insights for decision-making and the design of personalized marketing strategies. This segmentation will help understand purchasing patterns, platform interaction, and potential customer categories.\n",
    "\n",
    "The cleaned dataset presents the following relevant characteristics:\n",
    "\n",
    "**Dataset Size:** It contains exactly 55,002 records, representing a sufficiently large sample to derive representative clusters.\n",
    "\n",
    "**Variable Distributions:**\n",
    "\n",
    "- **Symmetrical:** `dias_primera_compra` and `info_perfil`. These columns show consistent behaviors and allow for hierarchical relationships between customers to be observed.\n",
    "\n",
    "- **Asymmetrical:** `n_clicks`, `n_visitas`, `monto_compras`, and `monto_descuentos`. These columns exhibit skewness toward extreme values, indicating behaviors of highly active customers or those with high purchasing power.\n",
    "\n",
    "**Outliers:** Present in `n_clicks`, `n_visitas`, `monto_compras`, and `monto_descuentos`, which may represent exceptional customers, such as frequent shoppers or significant consumers. There are no outliers in `dias_primera_compra` or `info_perfil`, reflecting more consistent distributions.\n",
    "\n",
    "Based on these characteristics, the selection of four clustering methods suitable for exploring significant patterns in this context will be theoretically justified."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploration of Clustering Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following describes the methods considered, along with their advantages, disadvantages, and justification for inclusion or exclusion in this project.\n",
    "\n",
    "##### K-Means\n",
    "\n",
    "**Description:** Divides the data into k clusters, minimizing internal variance within each group. It relies on Euclidean distance, making it particularly suitable for compact and spherical clusters.\n",
    "\n",
    "**Advantages:**\n",
    "\n",
    "- Efficient for large datasets due to its computational simplicity.\n",
    "\n",
    "- Easy to interpret and visualize.\n",
    "\n",
    "**Disadvantages:**\n",
    "\n",
    "- Sensitive to outliers, which can skew centroids toward extreme values.\n",
    "\n",
    "- Assumes clusters are spherical and homogeneous, which may not be suitable for columns like `monto_compras` and `monto_descuentos`.\n",
    "\n",
    "**Justification:** Included as a baseline method due to its simplicity and efficiency. Although sensitive to outliers, it provides a reference point for evaluating other methods.\n",
    "\n",
    "##### DBSCAN\n",
    "\n",
    "**Description:** Detects clusters based on density and classifies scattered points as noise. It is particularly useful for identifying arbitrarily shaped clusters.\n",
    "\n",
    "**Advantages:**\n",
    "\n",
    "- Naturally handles outliers by classifying them as noise.\n",
    "\n",
    "- Does not require predefining the number of clusters, allowing for greater exploratory flexibility.\n",
    "\n",
    "**Disadvantages:**\n",
    "\n",
    "- Sensitive to epsilon and minimum point parameters, which must be carefully tuned to avoid overfitting.\n",
    "\n",
    "- Limited scalability for very large datasets, though manageable for this project.\n",
    "\n",
    "**Justification:** Included for its ability to handle non-spherical distributions and robustness against outliers, making it especially relevant for `n_clicks`, `n_visitas`, and other skewed columns.\n",
    "\n",
    "##### Hierarchical Clustering (Agglomerative)\n",
    "\n",
    "**Description:** Builds a hierarchy of clusters by iteratively merging observations into larger groups. This allows relationships between data points to be visualized through a dendrogram.\n",
    "\n",
    "**Advantages:**\n",
    "\n",
    "- Provides a visual representation (dendrogram) that facilitates hierarchical interpretation.\n",
    "\n",
    "- Does not require predefining the number of clusters, allowing different levels of granularity to be explored.\n",
    "\n",
    "**Disadvantages:**\n",
    "\n",
    "- Computationally expensive for large datasets, though feasible with a representative sample.\n",
    "\n",
    "**Justification:** Included for its interpretability and ability to analyze hierarchical structures, particularly useful for symmetrical columns like `dias_primera_compra` and `info_perfil`, which may reflect temporal or profile patterns.\n",
    "\n",
    "##### Gaussian Mixture Models (GMM)\n",
    "\n",
    "**Description:** Models the data as a combination of Gaussian distributions, assigning probabilities to each point for belonging to a cluster.\n",
    "\n",
    "**Advantages:**\n",
    "\n",
    "- Flexible in handling elliptical or overlapping clusters.\n",
    "\n",
    "- Provides probabilities, allowing for more detailed interpretations of cluster membership.\n",
    "\n",
    "**Disadvantages:**\n",
    "\n",
    "- Requires specifying the number of clusters beforehand.\n",
    "\n",
    "- Sensitive to outliers, which can distort Gaussian distributions.\n",
    "\n",
    "**Justification:** Included for its flexibility in modeling complex distributions, especially useful for columns like `monto_compras` and `monto_descuentos`, which exhibit diverse behavioral patterns.\n",
    "\n",
    "##### OPTICS\n",
    "\n",
    "**Description:** Similar to DBSCAN but capable of identifying hierarchical structures in clusters with variable density.\n",
    "\n",
    "**Advantages:**\n",
    "\n",
    "- Detects clusters with variable densities, offering greater precision in some cases.\n",
    "\n",
    "- Handles outliers.\n",
    "\n",
    "**Disadvantages:**\n",
    "\n",
    "- Less interpretable than DBSCAN.\n",
    "\n",
    "- Computationally expensive for large datasets.\n",
    "\n",
    "**Justification:** Excluded due to its complexity and lower interpretability compared to DBSCAN.\n",
    "\n",
    "##### BIRCH\n",
    "\n",
    "**Description:** Designed for large datasets, it uses a tree structure to summarize data before clustering.\n",
    "\n",
    "**Advantages:**\n",
    "\n",
    "- Scalable for large datasets.\n",
    "\n",
    "- Handles outliers and reduces dimensionality.\n",
    "\n",
    "**Disadvantages:**\n",
    "\n",
    "- Less precise for complex clusters.\n",
    "\n",
    "**Justification:** Excluded due to lower interpretability and precision compared to other methods.\n",
    "\n",
    "##### Bisecting K-Means\n",
    "\n",
    "**Description:** A variant of K-Means that iteratively splits clusters to optimize grouping.\n",
    "\n",
    "**Advantages:**\n",
    "\n",
    "- More effective in some cases than traditional K-Means.\n",
    "\n",
    "- Scalable for large datasets.\n",
    "\n",
    "**Disadvantages:**\n",
    "\n",
    "- Less interpretable than K-Means.\n",
    "\n",
    "**Justification:** Excluded due to the simplicity and effectiveness of traditional K-Means in this context."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selected Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The methods selected for this project are:\n",
    "\n",
    "**K-Means:** For its efficiency, ease of interpretation, and applicability as a baseline method.\n",
    "\n",
    "**DBSCAN:** For its robustness against outliers and ability to handle non-spherical distributions.\n",
    "\n",
    "**Gaussian Mixture Models (GMM):** For its flexibility in modeling non-spherical and complex distributions.\n",
    "\n",
    "**Hierarchical Clustering (Agglomerative):** For its interpretability and ability to explore hierarchical structures, particularly in symmetrical variables.\n",
    "\n",
    "These methods represent a balance between efficiency, robustness, and interpretability, aligning with the dataset's characteristics and the project's objectives."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (customer_segmentation)",
   "language": "python",
   "name": "customer_segmentation"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
