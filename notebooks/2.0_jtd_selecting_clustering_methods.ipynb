{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Selecting Clustering Methods**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clustering is an unsupervised learning technique used to segment a dataset into groups or clusters based on the similarities between observations. In this project, the primary goal of clustering is to identify groups of customers with similar behaviors, enabling actionable insights for decision-making and the development of personalized marketing strategies. This segmentation will provide a deeper understanding of purchasing patterns, platform interactions, and potential customer categories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Dataset Characteristics**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dataset Size:** \n",
    "\n",
    "The clean dataset consists of 55,002 records, providing a robust sample size for identifying representative clusters.\n",
    "\n",
    "**Variable Distributions:**\n",
    "\n",
    "- **Symmetrical:** ``dias_primera_compra`` and ``info_perfil`` exhibit consistent and symmetrical distributions, making them suitable for hierarchical clustering methods that explore relationships between customers.\n",
    "\n",
    "- **Asymmetrical:** ``n_clicks``, ``n_visitas``, ``monto_compras``, and ``monto_descuentos`` display skewed distributions, with extreme values indicating highly active users or customers with significant purchasing power.\n",
    "\n",
    "**Outliers:**\n",
    "\n",
    "- **Present:** Outliers are observed in ``n_clicks``, ``n_visitas``, ``monto_compras``, and ``monto_descuentos``, representing exceptional customers such as frequent shoppers or high spenders.\n",
    "\n",
    "- **Not Present:** ``dias_primera_compra`` and ``info_perfil`` show no significant outliers, reflecting consistent patterns across the customer base."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Comparison of Clustering Methods**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following section outlines the clustering methods considered for this project, detailing their advantages, disadvantages, and the justification for their inclusion or exclusion. Each method was evaluated based on its compatibility with the dataset‚Äôs characteristics, such as variable distributions, presence of outliers, and the desired insights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| **Clustering Method**      | **Description**                                                                                                                                              | **Advantages**                                                                                                                                                                                                                     | **Disadvantages**                                                                                                                                                          | **Justification**                                                                                                                                                                                                                              | **Relevance for Dataset**                                                                                                            |\n",
    "|-----------------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------------------------|\n",
    "| **K-Means**                | Divides the data into k clusters, minimizing internal variance within each group. Relies on Euclidean distance, suitable for compact and spherical clusters.  | üü¢ Efficient for large datasets due to computational simplicity.<br>üü¢ Easy to interpret and visualize.                                                                                                                            | üî¥ Sensitive to outliers, which can skew centroids.<br>üî¥ Assumes spherical and homogeneous clusters, unsuitable for columns like `monto_compras` and `monto_descuentos`.  | ‚úî Included as a baseline method for simplicity and efficiency. Provides a reference point for evaluating other methods.                                                                                                                        | Suitable for symmetrical variables like `dias_primera_compra` and `info_perfil`, but sensitive to outliers in `n_clicks`.  |\n",
    "| **DBSCAN**                 | Detects clusters based on density, classifying scattered points as noise. Suitable for identifying arbitrarily shaped clusters.                               | üü¢ Naturally handles outliers by classifying them as noise.<br>üü¢ Does not require predefining the number of clusters, allowing greater exploratory flexibility.                                                                    | üî¥ Sensitive to epsilon and minimum point parameters.<br>üî¥ Limited scalability for very large datasets, though manageable for this project.                                | ‚úî Included for its ability to handle non-spherical distributions and robustness against outliers, especially for skewed columns like `n_clicks` and `monto_descuentos`.                                                                            | Highly relevant for `n_clicks` and `monto_descuentos`, which exhibit dense regions and outliers.                             |\n",
    "| **Hierarchical Clustering**| Builds a hierarchy of clusters by iteratively merging observations. Provides relationships through a dendrogram.                                            | üü¢ Provides a visual representation (dendrogram).<br>üü¢ Does not require predefining the number of clusters, enabling exploration of different levels of granularity.                                                              | üî¥ Computationally expensive for large datasets, though feasible with representative samples.                                                                               | ‚úî Included for its interpretability and ability to analyze symmetrical columns like `dias_primera_compra`, which may reflect temporal patterns in customer behavior.                                                                              | Ideal for `dias_primera_compra` and `info_perfil`, given their symmetry and hierarchical nature.                             |\n",
    "| **Gaussian Mixture Models**| Models data as a combination of Gaussian distributions, assigning probabilities to cluster membership.                                                       | üü¢ Flexible for elliptical or overlapping clusters.<br>üü¢ Provides probabilities for detailed cluster membership interpretation.                                                                                                    | üî¥ Requires specifying the number of clusters.<br>üî¥ Sensitive to outliers, which can distort Gaussian distributions.                                                        | ‚úî Included for its flexibility in modeling complex distributions, particularly for `monto_compras` and `monto_descuentos`, which show diverse patterns and overlapping behaviors.                                                                   | Effective for analyzing `monto_compras` and `monto_descuentos` due to their continuous and overlapping distributions.        |\n",
    "| **OPTICS**                 | Similar to DBSCAN but identifies hierarchical structures in clusters with variable density.                                                                 | üü¢ Detects clusters with variable densities.<br>üü¢ Handles outliers.                                                                                                                                                              | üî¥ Less interpretable than DBSCAN.<br>üî¥ Computationally expensive for large datasets.                                                                                       | ‚ùå Excluded due to its complexity and limited interpretability compared to DBSCAN, as well as the manageable density of the dataset‚Äôs clusters.                                                                                                  | Less relevant since DBSCAN can handle most cases effectively.                                                              |\n",
    "| **BIRCH**                  | Uses a tree structure to summarize data before clustering, designed for large datasets.                                                                     | üü¢ Scalable for large datasets.<br>üü¢ Handles outliers and reduces dimensionality.                                                                                                                                                  | üî¥ Less precise for complex clusters.                                                                                                                                      | ‚ùå Excluded due to its lower precision and interpretability compared to other methods.                                                                                                                    | Not as effective for highly overlapping or skewed data like `n_clicks` and `monto_descuentos`.                                |\n",
    "| **Bisecting K-Means**      | A variant of K-Means that iteratively splits clusters to optimize grouping.                                                                                  | üü¢ More effective in some cases than traditional K-Means.<br>üü¢ Scalable for large datasets.                                                                                                                                        | üî¥ Less interpretable than K-Means.                                                                                                                                       | ‚ùå Excluded due to the simplicity and effectiveness of traditional K-Means, which already meets the needs for this dataset.                                                                                                                      | Provides no significant improvement over K-Means for this dataset‚Äôs characteristics.                                      |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Selected Clustering Methods**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The methods selected for this project are:\n",
    "\n",
    "- **K-Means:** Selected for its computational efficiency, simplicity, and effectiveness as a baseline clustering method. It is particularly suited for symmetrical and compact clusters, making it a good starting point for comparison with more complex methods.\n",
    "\n",
    "- **DBSCAN:** Chosen for its robustness in handling outliers and its ability to identify arbitrarily shaped clusters. This method is especially relevant for skewed variables like `n_clicks` and `monto_descuentos`, where dense regions and outliers coexist.\n",
    "\n",
    "- **Gaussian Mixture Models (GMM):** Included for its flexibility in modeling complex and overlapping clusters. It is particularly suitable for asymmetrical distributions such as `monto_compras` and `monto_descuentos`, offering probabilistic insights into cluster memberships.\n",
    "\n",
    "- **Hierarchical Clustering (Agglomerative):** Added for its interpretability and hierarchical exploration capabilities, especially for variables like `dias_primera_compra` and `info_perfil`, which exhibit symmetrical and consistent patterns.\n",
    "\n",
    "Based on the dataset‚Äôs characteristics, these methods were chosen to align with its specific traits, such as symmetry, skewness, and the presence of outliers. This selection ensures a balanced approach to clustering, combining efficiency, robustness, and interpretability to derive meaningful patterns and actionable insights from the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Metrics for Evaluating Clustering Quality**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To assess the quality of the clusters generated by each method, the following evaluation metrics were selected. These metrics were chosen for their ability to measure both the compactness of clusters and their separation, aligning with the project's objective of identifying well-defined customer groups."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| **Metric**               | **Description**                                                                                                                                               | **Justification**                                                                                                                                                                                                                   |\n",
    "|---------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| **Silhouette Coefficient**| Measures how similar a data point is to its own cluster compared to other clusters. Ranges from -1 (poor clustering) to 1 (perfect clustering).                | Ideal for methods like K-Means and GMM, which rely on compactness and separation. It evaluates how well-defined clusters are and helps determine the appropriate number of clusters.                                               |\n",
    "| **Davies-Bouldin Index**  | Evaluates the average similarity ratio of each cluster with its most similar cluster. Lower values indicate better-defined clusters.                          | Particularly useful for comparing methods like DBSCAN and Hierarchical Clustering, where clusters may vary in shape and density. Emphasizes the distinctiveness of clusters, complementing the Silhouette Coefficient.             |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These metrics offer complementary perspectives: the Silhouette Coefficient evaluates intra-cluster compactness and inter-cluster separation, while the Davies-Bouldin Index emphasizes cluster distinctiveness. Together, they provide a comprehensive evaluation, accommodating the dataset's mix of symmetrical and asymmetrical distributions, as well as the presence of outliers. Their interpretability and actionable nature make them valuable for assessing cluster quality and guiding adjustments in method parameters or data preprocessing."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (customer_segmentation)",
   "language": "python",
   "name": "customer_segmentation"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
