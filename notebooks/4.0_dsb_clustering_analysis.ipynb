{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b375c3cf-9142-490d-8b70-3959bc946f02",
   "metadata": {},
   "source": [
    "### Clustering Analysis\n",
    "En esta sección se analizarán los clusters obtenidos del notebook 3.0\n",
    "\n",
    "#### Selección del dataframe con los mejores clusters\n",
    "Se seleccionará el dataframe con los mejores clusters de acuerdo con las métricas de evaluación de calidad que utilizamos en el notebook anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1027bbb-18a4-43dd-b444-151ad58fcd60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans, DBSCAN, AgglomerativeClustering\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c5c4a84-99f0-48d8-bd4a-c6e4c06216a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading cleaned dataset\n",
    "dataset_path = \"../data/processed/cleaned_dataset.csv\"\n",
    "df = pd.read_csv(dataset_path)\n",
    "df = df.drop(columns=[\"ID\", \"dias_primera_compra\", \"n_clicks\", \"info_perfil\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8d949e9-dbc3-4e33-b11d-b1393c1c4dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Util functions\n",
    "def scale_minmax(df, column):\n",
    "    scaler = MinMaxScaler()\n",
    "    df[column] = scaler.fit_transform(df[[column]])\n",
    "def visualize_clusters(df_scaled, df_objective, column):\n",
    "    pca = PCA(n_components=2)\n",
    "    principal_components = pca.fit_transform(df_scaled)\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.scatter(principal_components[:, 0], principal_components[:, 1], c=df_objective[column], cmap='viridis', s=1)\n",
    "    plt.title('Cluster Visualization (PCA)')\n",
    "    plt.xlabel('PCA Component 1')\n",
    "    plt.ylabel('PCA Component 2')\n",
    "    plt.colorbar(label='Cluster')\n",
    "    plt.show\n",
    "def evaluate_clusters(df_scaled, df_objective, column):\n",
    "    print(f\"Silhouette = {silhouette_score(df_scaled, df_objective[column]):.4f}\\n\"\n",
    "          f\"Davies-Bouldin = {davies_bouldin_score(df_scaled, df_objective[column]):.4f}\")\n",
    "    visualize_clusters(df_scaled, df_objective, column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2d96bcb-02e7-41f7-9b45-5c4e52e983db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling variables\n",
    "df_scaled = df.copy()\n",
    "for i in list(df.columns):\n",
    "    scale_minmax(df_scaled, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37998504-b31d-4a6f-8b16-a5313269eb4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-Means\n",
    "df_kmeans = df.copy()\n",
    "kmeans = KMeans(n_clusters=3).fit(df_scaled.values)\n",
    "df_kmeans[\"cluster\"] = kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "682d40e7-11ad-4457-980b-bea4695214af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DBSCAN\n",
    "df_dbscan = df.copy()\n",
    "dbscan = DBSCAN(eps = 0.04, min_samples = 50)\n",
    "df_dbscan['cluster'] = dbscan.fit_predict(df_scaled)\n",
    "scaled_db = df_scaled[df_dbscan[\"cluster\"] != -1]\n",
    "df_dbscan = df_dbscan[df_dbscan[\"cluster\"] != -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5da7eab4-4de6-4329-b276-7eda6b00a3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gaussian Mixture\n",
    "df_gaussi = df.copy()\n",
    "n_clusters_ = 3  \n",
    "gaussian = GaussianMixture(\n",
    "    n_components=n_clusters_, \n",
    "    covariance_type='full',  \n",
    "    init_params='kmeans',    \n",
    "    max_iter=100, \n",
    "    tol=1e-3, \n",
    "    random_state=42         \n",
    ")\n",
    "df_gaussi[\"cluster\"] = gaussian.fit_predict(df_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "22870608-11c3-4f30-a0c0-3d8958c76b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agglomerative\n",
    "df_agglom = df.copy()\n",
    "sample_size = 26000\n",
    "random_indexes = np.random.choice(df_scaled.shape[0], sample_size, replace=False)\n",
    "scaled_ag = df_scaled.iloc[random_indexes]\n",
    "df_agglom = df_agglom.iloc[random_indexes]\n",
    "agglomerative = AgglomerativeClustering(n_clusters=3, metric='euclidean', linkage='ward')\n",
    "df_agglom[\"cluster\"] = agglomerative.fit_predict(scaled_ag)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f254448a-d77d-4188-93da-82df1a69eec3",
   "metadata": {},
   "source": [
    "##### Evaluating clusters\n",
    "\n",
    "Con el siguiente código:\n",
    "```python\n",
    "print(\"Evaluation of K-Means\")\n",
    "evaluate_clusters(df_scaled, df_kmeans, \"cluster\")\n",
    "print(\"\\nEvaluation of DBSCAN\")\n",
    "evaluate_clusters(scaled_db, df_dbscan, \"cluster\")\n",
    "print(\"\\nEvaluation of Gaussian Mixture\")\n",
    "evaluate_clusters(df_scaled, df_gaussi, \"cluster\")\n",
    "print(\"\\nEvaluation of Agglomerative\")\n",
    "evaluate_clusters(scaled_ag, df_agglom, \"cluster\")\n",
    "```\n",
    "Se obtuvo la siguiente salida:\n",
    "```python\n",
    "Evaluation of K-Means\n",
    "    Silhouette = 0.6382\n",
    "    Davies-Bouldin = 0.5010\n",
    "\n",
    "Evaluation of DBSCAN\n",
    "    Silhouette = 0.6605\n",
    "    Davies-Bouldin = 0.4660\n",
    "\n",
    "Evaluation of Gaussian Mixture\n",
    "    Silhouette = 0.6328\n",
    "    Davies-Bouldin = 0.5062\n",
    "\n",
    "Evaluation of Agglomerative\n",
    "    Silhouette = 0.6346\n",
    "    Davies-Bouldin = 0.5064\n",
    "```\n",
    "Todos estos métodos fueron exhaustivamente probados y para el número de 3 clusters los resultados de las métricas fueron los mejores. Por lo tanto, analizaremos los resultados de los clusters retornados con DBSCAN, el cual fue el que tuvo los mejores scores de las métricas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "660ae59c-c291-47ce-bb87-9201dfa34b13",
   "metadata": {},
   "source": [
    "##### Analyzing the clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a98e28-4e45-4914-8b0e-1f9020244bbe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (customer_segmentation)",
   "language": "python",
   "name": "customer_segmentation"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
